#!/usr/bin/env python3
"""
vLLMä»£ç†æœåŠ¡å™¨å¯åŠ¨è„šæœ¬
"""

import sys
import os
import subprocess
import time
import requests

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

try:
    from config_manager import config
except ImportError as e:
    print(f"æ— æ³•å¯¼å…¥é…ç½®ç®¡ç†å™¨: {e}")
    print("è¯·ç¡®ä¿config_manager.pyæ–‡ä»¶å­˜åœ¨ä¸”è¯­æ³•æ­£ç¡®")
    sys.exit(1)

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
    required_packages = [
        'fastapi',
        'uvicorn',
        'requests',
        'pydantic'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
        print("pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True

def check_vllm_server():
    """æ£€æŸ¥vLLMæœåŠ¡å™¨æ˜¯å¦å¯è®¿é—®"""
    try:
        health_url = config.vllm_api_url.replace("/v1/chat/completions", "/health")
        response = requests.get(health_url, timeout=5)
        if response.status_code == 200:
            print("âœ… vLLMæœåŠ¡å™¨è¿æ¥æ­£å¸¸")
            return True
        else:
            print(f"âš ï¸  vLLMæœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°vLLMæœåŠ¡å™¨")
        print(f"   è¯·ç¡®ä¿vLLMæœåŠ¡å™¨æ­£åœ¨è¿è¡Œ: {config.vllm_api_url}")
        return False
    except Exception as e:
        print(f"âš ï¸  æ£€æŸ¥vLLMæœåŠ¡å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

def print_server_info():
    """æ‰“å°æœåŠ¡å™¨ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ğŸš€ vLLMä»£ç†æœåŠ¡å™¨é…ç½®ä¿¡æ¯")
    print("="*60)
    print(f"æœåŠ¡å™¨åœ°å€: http://{config.server_host}:{config.server_port}")
    print(f"vLLM APIåœ°å€: {config.vllm_api_url}")
    print(f"é»˜è®¤æ¨¡å‹: {config.default_model}")
    print(f"è¯·æ±‚è¶…æ—¶: {config.request_timeout}ç§’")
    print(f"æ—¥å¿—çº§åˆ«: {config.log_level}")
    print("="*60)

def print_api_endpoints():
    """æ‰“å°APIç«¯ç‚¹ä¿¡æ¯"""
    print("\nğŸ“‹ å¯ç”¨çš„APIç«¯ç‚¹:")
    print(f"   GET  /                    - æœåŠ¡å™¨çŠ¶æ€")
    print(f"   GET  /health              - å¥åº·æ£€æŸ¥")
    print(f"   POST /chat                - å®Œæ•´èŠå¤©æ¥å£")
    print(f"   POST /simple_chat         - ç®€åŒ–èŠå¤©æ¥å£")
    print(f"   GET  /models              - æ¨¡å‹åˆ—è¡¨")
    print(f"   GET  /config              - é…ç½®ä¿¡æ¯")
    print(f"   POST /generate/introduction - ç¤¾å›¢ä»‹ç»ç”Ÿæˆæ¥å£")
    print(f"   POST /generate/Slogan     - ç¤¾å›¢å£å·ç”Ÿæˆæ¥å£")
    print(f"   GET  /docs                - APIæ–‡æ¡£ (Swagger UI)")
    print(f"   GET  /redoc               - APIæ–‡æ¡£ (ReDoc)")

def start_server():
    """å¯åŠ¨æœåŠ¡å™¨"""
    print("\nğŸ”„ æ­£åœ¨å¯åŠ¨vLLMä»£ç†æœåŠ¡å™¨...")
    
    try:
        # å¯¼å…¥å¹¶è¿è¡ŒæœåŠ¡å™¨
        from vllm_proxy_server import app
        import uvicorn
        
        print(f"âœ… æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")
        print(f"ğŸŒ è®¿é—®åœ°å€: http://{config.server_host}:{config.server_port}")
        print(f"ğŸ“– APIæ–‡æ¡£: http://{config.server_host}:{config.server_port}/docs")
        print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
        
        uvicorn.run(
            app,
            host=config.server_host,
            port=config.server_port,
            log_level=config.log_level.lower()
        )
        
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ æœåŠ¡å™¨å·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨æœåŠ¡å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ vLLMä»£ç†æœåŠ¡å™¨å¯åŠ¨å™¨")
    print("="*40)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    # æ£€æŸ¥vLLMæœåŠ¡å™¨
    print("\nğŸ” æ£€æŸ¥vLLMæœåŠ¡å™¨è¿æ¥...")
    vllm_available = check_vllm_server()
    
    # æ‰“å°æœåŠ¡å™¨ä¿¡æ¯
    print_server_info()
    
    # æ‰“å°APIç«¯ç‚¹
    print_api_endpoints()
    
    if not vllm_available:
        print("\nâš ï¸  è­¦å‘Š: vLLMæœåŠ¡å™¨ä¸å¯ç”¨")
        print("   æœåŠ¡å™¨ä»å°†å¯åŠ¨ï¼Œä½†èŠå¤©åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        print("   è¯·ç¡®ä¿vLLMæœåŠ¡å™¨æ­£åœ¨è¿è¡Œåå†ä½¿ç”¨èŠå¤©åŠŸèƒ½")
        
        response = input("\næ˜¯å¦ç»§ç»­å¯åŠ¨æœåŠ¡å™¨? (y/N): ")
        if response.lower() != 'y':
            print("å¯åŠ¨å·²å–æ¶ˆ")
            sys.exit(0)
    
    # å¯åŠ¨æœåŠ¡å™¨
    start_server()

if __name__ == "__main__":
    main() 